{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "#import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab as pl\n",
    "from pandas import ExcelFile\n",
    "import xlrd\n",
    "from sklearn import preprocessing\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file name is : WeatherAUS-Final-PCA-sample -2.xlsx\n",
      "The sheet's name is: Data\n",
      "The matrix size is: (2996, 9)\n",
      "The file has: 26964 data points.\n",
      "*******************************************\n"
     ]
    }
   ],
   "source": [
    "#Openning Excel sheet and importing the data\n",
    "\"\"\"\n",
    "Open files and create the data frame from the excel sheet.\n",
    "there are 24 columns and 142193 observations.\n",
    "\"\"\"\n",
    "#Assign spreadsheet file name to 'file'.\n",
    "#file = 'Sample 1.xlsx'\n",
    "file = 'WeatherAUS-Final-PCA-sample -2.xlsx'\n",
    "\n",
    "#Load spreadsheet.\n",
    "Excel_File = pd.ExcelFile (file)\n",
    "print \"The file name is :\", file\n",
    "print \"The sheet's name is:\", \"Data\"\n",
    "\n",
    "#Load a sheet into a dataframe by name Data:\n",
    "Data = Excel_File.parse('Data')\n",
    "print \"The matrix size is:\", np.shape (Data)\n",
    "print \"The file has:\", np.size (Data), \"data points.\"\n",
    "print \"*******************************************\"\n",
    "\n",
    "#Data\n",
    "X = Data.drop('label', axis=1)  \n",
    "y = Data['label']\n",
    "#print X.head()\n",
    "#print y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.550179</td>\n",
       "      <td>3.875191</td>\n",
       "      <td>-1.487168</td>\n",
       "      <td>-0.618093</td>\n",
       "      <td>0.442401</td>\n",
       "      <td>0.396120</td>\n",
       "      <td>-0.033091</td>\n",
       "      <td>0.354812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.732818</td>\n",
       "      <td>0.616874</td>\n",
       "      <td>0.822514</td>\n",
       "      <td>-0.172073</td>\n",
       "      <td>0.923700</td>\n",
       "      <td>-0.527360</td>\n",
       "      <td>-0.010588</td>\n",
       "      <td>-0.160444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.014773</td>\n",
       "      <td>-0.489348</td>\n",
       "      <td>0.411100</td>\n",
       "      <td>0.892878</td>\n",
       "      <td>-0.020893</td>\n",
       "      <td>-0.324203</td>\n",
       "      <td>0.278403</td>\n",
       "      <td>0.542735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.317208</td>\n",
       "      <td>-0.076727</td>\n",
       "      <td>-0.457830</td>\n",
       "      <td>0.605717</td>\n",
       "      <td>0.122668</td>\n",
       "      <td>-0.318523</td>\n",
       "      <td>0.609186</td>\n",
       "      <td>0.625106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.639942</td>\n",
       "      <td>1.995414</td>\n",
       "      <td>0.273545</td>\n",
       "      <td>0.170543</td>\n",
       "      <td>-0.364265</td>\n",
       "      <td>-0.276448</td>\n",
       "      <td>0.660561</td>\n",
       "      <td>0.831699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0 -0.550179  3.875191 -1.487168 -0.618093  0.442401  0.396120 -0.033091   \n",
       "1 -1.732818  0.616874  0.822514 -0.172073  0.923700 -0.527360 -0.010588   \n",
       "2 -2.014773 -0.489348  0.411100  0.892878 -0.020893 -0.324203  0.278403   \n",
       "3 -1.317208 -0.076727 -0.457830  0.605717  0.122668 -0.318523  0.609186   \n",
       "4 -0.639942  1.995414  0.273545  0.170543 -0.364265 -0.276448  0.660561   \n",
       "\n",
       "          7  \n",
       "0  0.354812  \n",
       "1 -0.160444  \n",
       "2  0.542735  \n",
       "3  0.625106  \n",
       "4  0.831699  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(ratio='minority')\n",
    "X_sm, y_sm = smote.fit_sample(X, y)\n",
    "X_sm = pd.DataFrame(X_sm)\n",
    "y_sm = pd.DataFrame(y_sm)\n",
    "\n",
    "#plot_2d_space(X_sm, y_sm, 'SMOTE over-sampling')\n",
    "X_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         P1        P2        P3        P4        P5        P6        P7  \\\n",
      "0 -0.550179  3.875191 -1.487168 -0.618093  0.442401  0.396120 -0.033091   \n",
      "1 -1.732818  0.616874  0.822514 -0.172073  0.923700 -0.527360 -0.010588   \n",
      "2 -2.014773 -0.489348  0.411100  0.892878 -0.020893 -0.324203  0.278403   \n",
      "3 -1.317208 -0.076727 -0.457830  0.605717  0.122668 -0.318523  0.609186   \n",
      "4 -0.639942  1.995414  0.273545  0.170543 -0.364265 -0.276448  0.660561   \n",
      "\n",
      "         P8  \n",
      "0  0.354812  \n",
      "1 -0.160444  \n",
      "2  0.542735  \n",
      "3  0.625106  \n",
      "4  0.831699  \n",
      "   label\n",
      "0      1\n",
      "1     -1\n",
      "2     -1\n",
      "3     -1\n",
      "4     -1\n"
     ]
    }
   ],
   "source": [
    "X = X_sm\n",
    "X.columns = ['P1', 'P2','P3','P4','P5','P6','P7','P8']\n",
    "print X.head()\n",
    "y = y_sm\n",
    "y.columns = ['label']\n",
    "print y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Divide data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#P stands for Primary sets \n",
    "X_train_p, X_test_p, y_train_p, y_test_p = train_test_split(X, y, test_size = 0.20, random_state = 1) \n",
    "\n",
    "X_train = X_train_p\n",
    "X_test = X_test_p\n",
    "y_train = y_train_p\n",
    "y_test = y_test_p \n",
    "\n",
    "X_train = pd.DataFrame(X_train)\n",
    "X_train = X_train.reset_index()\n",
    "X_train = X_train.drop('index', axis=1)                            \n",
    "print X_train.shape\n",
    "\n",
    "X_test = pd.DataFrame(X_test)\n",
    "X_test = X_test.reset_index()\n",
    "X_test = X_test.drop('index', axis=1)                            \n",
    "print X_test.shape\n",
    "\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_train = y_train.reset_index()\n",
    "y_train = y_train.drop('index', axis=1)\n",
    "\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test = y_test.reset_index()\n",
    "y_test = y_test.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the kernels from Training Data\n",
    "#Defining Linear Kernel\n",
    "from numpy import linalg\n",
    "\n",
    "X1 = X_train\n",
    "X2 = pd.DataFrame.transpose(X_train)\n",
    "#print X1.shape\n",
    "#print X2.shape\n",
    "K_Linear = np.dot(X1, X2)\n",
    "\n",
    "print \"The size of the matrix is:\" ,np.shape(K_Linear)\n",
    "\n",
    "#Creating dataframes\n",
    "Kernel_1 = pd.DataFrame(K_Linear)\n",
    "\n",
    "#Defining the kernels from Testing Data\n",
    "#Defining Linear Kernel\n",
    "from numpy import linalg\n",
    "\n",
    "X1 = (X_train)\n",
    "X2 = pd.DataFrame.transpose(X_test)\n",
    "K_Linear = np.dot(X1, X2)\n",
    "\n",
    "print \"The size of the matrix is:\" ,np.shape(K_Linear)\n",
    "\n",
    "#Creating dataframes\n",
    "Kernel_1_T = pd.DataFrame(K_Linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Optimization model\n",
    "from gurobipy import *\n",
    "model = Model (\"Kernelizid multi-objective SVM\")\n",
    "model.params.presolve = 0\n",
    "\n",
    "#Variables\n",
    "A = {} #coefficients in kernelized format\n",
    "\n",
    "S = {} #vector of deviations \n",
    "\n",
    "B = {} #off-set\n",
    "\n",
    "#The counter in the dataset\n",
    "Index = X_train.index \n",
    "print Index\n",
    "\n",
    "#vtype= GRB.INTEGER, GRB.CONTINUOUS, GRB.BINARY    \n",
    "for i in Index: \n",
    "    A[i] = model.addVar(vtype= GRB.CONTINUOUS ,lb= 0, ub= GRB.INFINITY)\n",
    "\n",
    "for i in Index: \n",
    "    S[i] = model.addVar(vtype= GRB.CONTINUOUS ,lb= 0, ub= GRB.INFINITY)\n",
    "\n",
    "for i in Index:\n",
    "    B[i] = model.addVar(vtype= GRB.CONTINUOUS ,lb= 0 , ub= GRB.INFINITY)    \n",
    "    \n",
    "model.modelSense = GRB.MINIMIZE   #GRB.MAXIMIZE  \n",
    "model.update()\n",
    "\n",
    "\n",
    "for i in Index:\n",
    "    model.addConstr ( (y_train.at[i,\"label\"]*(quicksum((A[j])*Kernel_1.at[i,j] for j in Index) + B[i])) >= (1 - S[i]))\n",
    "\n",
    "Obj_Function = quicksum ( A[i] for i in Index)\n",
    "Deviations = quicksum (S[i] for i in Index)\n",
    "  \n",
    "L = 0.9999\n",
    "\n",
    "OBJ1 = L*Obj_Function\n",
    "OBJ2 = (1-L)*Deviations    \n",
    "objective = OBJ1 + OBJ2\n",
    "        \n",
    "model.setObjective (objective)\n",
    "model.optimize()            \n",
    "\n",
    "#Printing outputs \n",
    "if model.status==GRB.OPTIMAL:\n",
    "    print \"the model is optimal.\"\n",
    "    print (\"Optimal value:\", model.objVal) \n",
    "    print \"****************************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the hyperplaen\n",
    "#Calculating the bias or off-set\n",
    "B_list = []\n",
    "for i in Index:\n",
    "    B_list.extend([(B[i].x)])\n",
    "Average = sum(B_list)/len(B_list)\n",
    "Bias = Average \n",
    "#print Bias\n",
    "\n",
    "#Calculating the weight vector\n",
    "Weight_list = []\n",
    "for i in Index:\n",
    "    Weight_list.extend([(A[i].x)])\n",
    "#print Weight_list\n",
    "\n",
    "Weight_DF = pd.DataFrame(Weight_list)\n",
    "Weight_DF.columns = ['Weight']\n",
    "for i in Index:\n",
    "    Y = y_train.at[i, 'label']*Weight_DF.at[i, 'Weight'] \n",
    "#Weight_DF = pd.DataFrame.transpose(Weight_DF)\n",
    "#print Weight_DF\n",
    "print np.shape(Weight_DF)\n",
    "\n",
    "#Linear Kernel\n",
    "print np.shape(Kernel_1_T)\n",
    "\n",
    "Kernel_1_T = pd.DataFrame.transpose(Kernel_1_T)\n",
    "\n",
    "X = np.dot(Kernel_1_T, Weight_DF)\n",
    "#print X\n",
    "X1 = pd.DataFrame(X, columns = ['X1'])\n",
    "\n",
    "#H = Hyperplane\n",
    "H = X1.add(Bias)\n",
    "#print \"The vector of hyperplane is:\"\n",
    "#print H\n",
    "y_pred = []\n",
    "\n",
    "#Testing\n",
    "for i in H.index:\n",
    "    if H.at[i,\"X1\"] > 0:\n",
    "        y_pred.append(1)\n",
    "    if H.at[i,\"X1\"] < 0:\n",
    "        y_pred.append(-1)\n",
    "    if H.at[i,\"X1\"] == 0:\n",
    "        print i, \"This point is a support vector.\"        \n",
    "#print y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy: how often is the classifier correct?\n",
    "SVM_Linear_test_accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model Precision: what percentage of positive tuples are labeled as such?\n",
    "SVM_Linear_test_precision = metrics.precision_score(y_test, y_pred)\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "\n",
    "# Model Recall: what percentage of positive tuples are labelled as such?\n",
    "SVM_Linear_test_recall = metrics.recall_score(y_test, y_pred)\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "#Model F-measure:Compute the F1 score, also known as balanced F-score or F-measure\n",
    "F1 = 2 * (metrics.precision_score(y_test, y_pred) * metrics.recall_score\n",
    "          (y_test, y_pred)) / (metrics.precision_score(y_test, y_pred) + metrics.recall_score(y_test, y_pred))\n",
    "SVM_Linear_test_f1 = F1\n",
    "print ('F-Measure:', F1)\n",
    "\n",
    "#Model G-mean\n",
    "SVM_Linear_test_Gmean  = geometric_mean_score(y_test, y_pred)\n",
    "print ('Geometric mean:', geometric_mean_score(y_test, y_pred))\n",
    "print \"*******************************************\"\n",
    "#Evaluating the results\n",
    "\"\"\"Confusion matrix, precision, recall, and F1 measures \n",
    "are the most commonly used metrics for classification tasks\"\"\"\n",
    "\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report_imbalanced(y_test, y_pred,     target_names=target_names))\n",
    "print \"*******************************************\"\n",
    "\n",
    "#Confusion matrix using pyplot \n",
    "cm_SVC_linear = confusion_matrix(y_test, y_pred)\n",
    "sb.set(style=\"whitegrid\",font='sans-serif', font_scale=1.3)\n",
    "ax= plt.subplot()\n",
    "sb.heatmap(cm_SVC_linear, annot=True, ax = ax, cmap='coolwarm',fmt='g',linewidths=0.5 ) #annot=True to annotate cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(y_pred, y_test)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=1, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=1, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
